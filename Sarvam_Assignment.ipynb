{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3+7i1xyxq6UcyB9+Hffpq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushichadha/Einops-implementation-/blob/main/Sarvam_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from functools import reduce\n",
        "import operator\n",
        "from typing import List, Tuple, Dict, Union, Any, Optional\n",
        "\n",
        "def rearrange(tensor: np.ndarray, pattern: str, debug: bool = False, **axes_lengths) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Rearranges the tensor according to an Einstein notation–inspired pattern.\n",
        "\n",
        "    Supports:\n",
        "      • Transposition (e.g., \"h w -> w h\")\n",
        "      • Splitting axes (e.g., \"(h w) c -> h w c\", with h provided)\n",
        "      • Merging axes (e.g., \"a b c -> (a b) c\")\n",
        "      • Repeating axes (e.g., \"a 1 c -> a b c\", with b provided)\n",
        "      • Ellipsis for batch dimensions (e.g., \"... h w -> ... (h w)\")\n",
        "\n",
        "    Parameters:\n",
        "      tensor (np.ndarray): The input tensor.\n",
        "      pattern (str): The rearrangement pattern string.\n",
        "      debug (bool): If True, print debug information.\n",
        "      **axes_lengths: Additional dimensions needed for splitting or repeating.\n",
        "\n",
        "    Returns:\n",
        "      np.ndarray: The rearranged tensor.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If the pattern format is invalid or dimensions don't match.\n",
        "      IndexError: If the tensor doesn't have enough dimensions for the pattern.\n",
        "    \"\"\"\n",
        "    if '->' not in pattern:\n",
        "        raise ValueError(\"Pattern must contain '->' to separate input and output axes\")\n",
        "\n",
        "    input_pattern, output_pattern = map(str.strip, pattern.split('->'))\n",
        "    input_tokens = parse_tokens(input_pattern)\n",
        "    output_tokens = parse_tokens(output_pattern)\n",
        "\n",
        "    # Check for duplicate tokens in output\n",
        "    flat_output = flatten_list(output_tokens)\n",
        "    seen = set()\n",
        "    for token in flat_output:\n",
        "        if token in seen:\n",
        "            raise ValueError(f\"Duplicate token '{token}' found in output pattern\")\n",
        "        seen.add(token)\n",
        "\n",
        "    has_ellipsis = '...' in input_pattern\n",
        "    explicit_dims = sum(1 for token in input_tokens if token != '...')\n",
        "    ellipsis_dims = len(tensor.shape) - explicit_dims if has_ellipsis else 0\n",
        "\n",
        "    tensor, input_mapping = process_input_groups(tensor, input_tokens, axes_lengths, ellipsis_dims)\n",
        "    flat_input = flatten_list(input_tokens)\n",
        "\n",
        "    if all(not isinstance(tok, list) for tok in output_tokens) and set(flat_input) == set(flat_output) and len(flat_input) == len(flat_output):\n",
        "        perm = [flat_input.index(token) for token in flat_output]\n",
        "        tensor = np.transpose(tensor, axes=perm)\n",
        "    else:\n",
        "        output_shape = compute_output_shape(output_tokens, input_mapping, axes_lengths, ellipsis_dims)\n",
        "\n",
        "        if np.prod(tensor.shape) != np.prod(output_shape):\n",
        "            raise ValueError(f\"Total elements mismatch: input {tensor.shape} ({np.prod(tensor.shape)}) vs output {output_shape} ({np.prod(output_shape)})\")\n",
        "\n",
        "        if debug:\n",
        "            print(f\"[Debug] Input pattern tokens: {input_tokens}\")\n",
        "            print(f\"[Debug] Output pattern tokens: {output_tokens}\")\n",
        "            print(f\"[Debug] Inferred input mapping: {input_mapping}\")\n",
        "            print(f\"[Debug] Reshaping to: {output_shape}\")\n",
        "\n",
        "        tensor = tensor.reshape(output_shape)\n",
        "\n",
        "    tensor = process_repeating_axes(tensor, flat_input, flat_output, axes_lengths)\n",
        "    return tensor\n",
        "\n",
        "# ------------------- Helper Functions -------------------\n",
        "\n",
        "def parse_tokens(pattern: str) -> List[Union[str, List[str]]]:\n",
        "    \"\"\"\n",
        "    Parse a pattern string into tokens, handling groups in parentheses.\n",
        "\n",
        "    Args:\n",
        "        pattern (str): The pattern string to parse.\n",
        "\n",
        "    Returns:\n",
        "        List[Union[str, List[str]]]: A list of tokens, where each token is either a string or a list of tokens (for grouped dimensions).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If there are mismatched parentheses in the pattern.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    token = \"\"\n",
        "    i = 0\n",
        "    while i < len(pattern):\n",
        "        c = pattern[i]\n",
        "        if c == '(':\n",
        "            if token:\n",
        "                tokens.append(token)\n",
        "                token = \"\"\n",
        "            group, j = parse_group(pattern, i)\n",
        "            tokens.append(group)\n",
        "            i = j\n",
        "        elif c.isspace():\n",
        "            if token:\n",
        "                tokens.append(token)\n",
        "                token = \"\"\n",
        "            i += 1\n",
        "        else:\n",
        "            token += c\n",
        "            i += 1\n",
        "    if token:\n",
        "        tokens.append(token)\n",
        "    return tokens\n",
        "\n",
        "def parse_group(pattern: str, start: int) -> Tuple[List[str], int]:\n",
        "    \"\"\"\n",
        "    Parse a group enclosed in parentheses within a pattern string.\n",
        "\n",
        "    Args:\n",
        "        pattern (str): The full pattern string.\n",
        "        start (int): The starting index of the opening parenthesis.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], int]: A tuple containing (tokens_list, end_index), where tokens_list is the list of\n",
        "                               parsed tokens inside the parentheses and end_index is the index after the closing parenthesis.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If there are mismatched parentheses in the pattern.\n",
        "    \"\"\"\n",
        "    assert pattern[start] == '('\n",
        "    tokens = []\n",
        "    token = \"\"\n",
        "    i = start + 1\n",
        "    while i < len(pattern):\n",
        "        c = pattern[i]\n",
        "        if c == ')':\n",
        "            if token:\n",
        "                tokens.append(token)\n",
        "            return tokens, i + 1\n",
        "        elif c.isspace():\n",
        "            if token:\n",
        "                tokens.append(token)\n",
        "                token = \"\"\n",
        "            i += 1\n",
        "        else:\n",
        "            token += c\n",
        "            i += 1\n",
        "    raise ValueError(\"Mismatched parentheses in pattern\")\n",
        "\n",
        "def flatten_list(tokens: List[Any]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Flatten a nested list of tokens into a single list.\n",
        "\n",
        "    Args:\n",
        "        tokens (List[Any]): A list of tokens, potentially containing nested lists.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A flattened list where all nested lists have been expanded.\n",
        "    \"\"\"\n",
        "    flat = []\n",
        "    for token in tokens:\n",
        "        if isinstance(token, list):\n",
        "            flat.extend(flatten_list(token))\n",
        "        else:\n",
        "            flat.append(token)\n",
        "    return flat\n",
        "\n",
        "def process_input_groups(tensor: np.ndarray,\n",
        "                         tokens: List[Union[str, List[str]]],\n",
        "                         axes_lengths: Dict[str, int],\n",
        "                         ellipsis_dims: int) -> Tuple[np.ndarray, Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Process input tokens to reshape the tensor according to specified groupings.\n",
        "\n",
        "    Args:\n",
        "        tensor (np.ndarray): The input tensor.\n",
        "        tokens (List[Union[str, List[str]]]): The parsed input pattern tokens.\n",
        "        axes_lengths (Dict[str, int]): Dictionary of known dimension sizes.\n",
        "        ellipsis_dims (int): Number of dimensions represented by ellipsis.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, Dict[str, int]]: A tuple containing (reshaped_tensor, dimension_mapping), where dimension_mapping\n",
        "                                           is a dictionary mapping token names to their sizes.\n",
        "\n",
        "    Raises:\n",
        "        IndexError: If the tensor doesn't have enough dimensions for the pattern.\n",
        "        ValueError: If dimensions cannot be split correctly or not all dimensions are used.\n",
        "    \"\"\"\n",
        "    shape = list(tensor.shape)\n",
        "    new_shape = []\n",
        "    axis_index = 0\n",
        "    mapping: Dict[str, Any] = {}\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == '...':\n",
        "            ellipsis_start = axis_index\n",
        "            ellipsis_end = axis_index + ellipsis_dims\n",
        "            new_shape.extend(shape[ellipsis_start:ellipsis_end])\n",
        "            mapping['...'] = shape[ellipsis_start:ellipsis_end]\n",
        "            axis_index = ellipsis_end\n",
        "        elif isinstance(token, list):\n",
        "            if axis_index >= len(shape):\n",
        "                raise IndexError(f\"Not enough dimensions in tensor shape {shape} for pattern {tokens}\")\n",
        "            total = shape[axis_index]\n",
        "            dims: List[Optional[int]] = []\n",
        "            unspecified = []\n",
        "\n",
        "            for subtoken in token:\n",
        "                if subtoken in axes_lengths:\n",
        "                    dims.append(axes_lengths[subtoken])\n",
        "                    mapping[subtoken] = axes_lengths[subtoken]\n",
        "                elif re.match(r'^\\d+$', subtoken):\n",
        "                    dims.append(int(subtoken))\n",
        "                    mapping[subtoken] = int(subtoken)\n",
        "                else:\n",
        "                    dims.append(None)\n",
        "                    unspecified.append(subtoken)\n",
        "\n",
        "            if dims.count(None) == 1:\n",
        "                specified = reduce(operator.mul, [d for d in dims if d is not None], 1)\n",
        "                if total % specified != 0:\n",
        "                    raise ValueError(f\"Cannot split dimension {total} with specified product {specified}\")\n",
        "                inferred = total // specified\n",
        "                dims = [inferred if d is None else d for d in dims]\n",
        "                for i, subtoken in enumerate(token):\n",
        "                    if subtoken not in mapping and subtoken not in axes_lengths and not re.match(r'^\\d+$', subtoken):\n",
        "                        mapping[subtoken] = dims[i]\n",
        "            elif dims.count(None) > 1:\n",
        "                raise ValueError(f\"Multiple unspecified dimensions in group {token}\")\n",
        "\n",
        "            if reduce(operator.mul, dims, 1) != total:\n",
        "                raise ValueError(f\"Product of dimensions {dims} does not match size {total}\")\n",
        "\n",
        "            new_shape.extend(dims)\n",
        "            axis_index += 1\n",
        "        else:\n",
        "            if axis_index >= len(shape):\n",
        "                raise IndexError(f\"Not enough dimensions in tensor shape {shape} for pattern {tokens}\")\n",
        "            new_shape.append(shape[axis_index])\n",
        "            if re.match(r'^\\d+$', token):\n",
        "                mapping[token] = int(token)\n",
        "            elif token in axes_lengths:\n",
        "                mapping[token] = axes_lengths[token]\n",
        "            else:\n",
        "                mapping[token] = shape[axis_index]\n",
        "            axis_index += 1\n",
        "\n",
        "    if axis_index != len(shape):\n",
        "        raise ValueError(f\"Not all dimensions in {shape} were used in the pattern {tokens}\")\n",
        "\n",
        "    return tensor.reshape(new_shape), mapping\n",
        "\n",
        "def compute_output_shape(tokens: List[Union[str, List[str]]],\n",
        "                         mapping: Dict[str, Any],\n",
        "                         axes_lengths: Dict[str, int],\n",
        "                         ellipsis_dims: int) -> Tuple[int, ...]:\n",
        "    \"\"\"\n",
        "    Compute the output shape based on output tokens and dimension mappings.\n",
        "\n",
        "    Args:\n",
        "        tokens (List[Union[str, List[str]]]): The parsed output pattern tokens.\n",
        "        mapping (Dict[str, Any]): Dictionary mapping dimension names to their sizes.\n",
        "        axes_lengths (Dict[str, int]): Dictionary of known dimension sizes.\n",
        "        ellipsis_dims (int): Number of dimensions represented by ellipsis.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[int, ...]: The output shape as a tuple of integers.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an unknown token is found in the output pattern.\n",
        "    \"\"\"\n",
        "    shape = []\n",
        "    for token in tokens:\n",
        "        if token == '...':\n",
        "            shape.extend(mapping.get('...', [1] * ellipsis_dims))\n",
        "        elif isinstance(token, list):\n",
        "            prod = 1\n",
        "            for subtoken in token:\n",
        "                if re.match(r'^\\d+$', subtoken):\n",
        "                    prod *= int(subtoken)\n",
        "                elif subtoken in mapping:\n",
        "                    prod *= mapping[subtoken]\n",
        "                elif subtoken in axes_lengths:\n",
        "                    prod *= axes_lengths[subtoken]\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown token '{subtoken}' in output pattern\")\n",
        "            shape.append(prod)\n",
        "        else:\n",
        "            if re.match(r'^\\d+$', token):\n",
        "                shape.append(int(token))\n",
        "            elif token in mapping:\n",
        "                shape.append(mapping[token])\n",
        "            elif token in axes_lengths:\n",
        "                shape.append(1)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown token '{token}' in output pattern\")\n",
        "    return tuple(shape)\n",
        "\n",
        "def process_repeating_axes(tensor: np.ndarray,\n",
        "                          input_flat: List[str],\n",
        "                          output_flat: List[str],\n",
        "                          axes_lengths: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Process repeating axes in the output pattern.\n",
        "\n",
        "    This function handles tokens that appear in the output pattern but not in the input pattern,\n",
        "    repeating the corresponding dimensions according to the specified axes_lengths.\n",
        "\n",
        "    Args:\n",
        "        tensor (np.ndarray): The input tensor after reshaping.\n",
        "        input_flat (List[str]): Flattened list of input tokens.\n",
        "        output_flat (List[str]): Flattened list of output tokens.\n",
        "        axes_lengths (Dict[str, int]): Dictionary of known dimension sizes.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The tensor with repeated dimensions as needed.\n",
        "    \"\"\"\n",
        "    input_flat = [token for token in input_flat if token != '...']\n",
        "    output_flat = [token for token in output_flat if token != '...']\n",
        "    for i, token in enumerate(output_flat):\n",
        "        if token not in input_flat and token in axes_lengths:\n",
        "            tensor = np.repeat(tensor, axes_lengths[token], axis=i)\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "TnIdf3LnAZlA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Unit Tests -------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Positive Tests\n",
        "    x = np.random.rand(3, 4)\n",
        "    assert rearrange(x, 'h w -> w h').shape == (4, 3)\n",
        "\n",
        "    x = np.random.rand(12, 10)\n",
        "    assert rearrange(x, '(h w) c -> h w c', h=3).shape == (3, 4, 10)\n",
        "\n",
        "    x = np.random.rand(3, 4, 5)\n",
        "    assert rearrange(x, 'a b c -> (a b) c').shape == (12, 5)\n",
        "\n",
        "    x = np.random.rand(3, 1, 5)\n",
        "    assert rearrange(x, 'a 1 c -> a b c', b=4).shape == (3, 4, 5)\n",
        "\n",
        "    x = np.random.rand(2, 3, 4, 5)\n",
        "    assert rearrange(x, '... h w -> ... (h w)').shape == (2, 3, 20)\n",
        "\n",
        "    print(\"✅ All positive tests passed.\")\n",
        "\n",
        "    # Negative Tests\n",
        "    try:\n",
        "        rearrange(np.random.rand(12, 10), '(h w) c -> h w c')\n",
        "    except ValueError as e:\n",
        "        print(\"Caught expected error:\", e)\n",
        "\n",
        "    try:\n",
        "        rearrange(np.random.rand(3, 4), 'a b -> (a b c)')\n",
        "    except ValueError as e:\n",
        "        print(\"Caught expected error:\", e)\n",
        "\n",
        "    try:\n",
        "        rearrange(np.random.rand(2, 2), 'a b -> a a b')\n",
        "    except ValueError as e:\n",
        "        print(\"Caught expected error:\", e)\n",
        "\n",
        "    print(\"✅ All negative tests passed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epYU3KJ395BD",
        "outputId": "4caae1a7-0c93-41bd-ace9-0e7d45c4880b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All positive tests passed.\n",
            "Caught expected error: Multiple unspecified dimensions in group ['h', 'w']\n",
            "Caught expected error: Unknown token 'c' in output pattern\n",
            "Caught expected error: Duplicate token 'a' found in output pattern\n",
            "✅ All negative tests passed.\n"
          ]
        }
      ]
    }
  ]
}